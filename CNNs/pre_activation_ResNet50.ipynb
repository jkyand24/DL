{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Activation ResNet\n",
    "기존의 residual에서 순서를 바꿔 성능 향상 \n",
    "- Batch Normalization -> 활성화 함수 -> convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-4         [-1, 64, 112, 112]               0\n",
      "       BatchNorm2d-5         [-1, 64, 112, 112]             128\n",
      "              ReLU-6         [-1, 64, 112, 112]               0\n",
      "            Conv2d-7         [-1, 64, 112, 112]           4,160\n",
      "       BatchNorm2d-8         [-1, 64, 112, 112]             128\n",
      "              ReLU-9         [-1, 64, 112, 112]               0\n",
      "           Conv2d-10         [-1, 64, 112, 112]          36,928\n",
      "      BatchNorm2d-11         [-1, 64, 112, 112]             128\n",
      "             ReLU-12         [-1, 64, 112, 112]               0\n",
      "           Conv2d-13        [-1, 256, 112, 112]          16,640\n",
      "           Conv2d-14        [-1, 256, 112, 112]          16,640\n",
      "       BottleNeck-15        [-1, 256, 112, 112]               0\n",
      "      BatchNorm2d-16        [-1, 256, 112, 112]             512\n",
      "             ReLU-17        [-1, 256, 112, 112]               0\n",
      "           Conv2d-18         [-1, 64, 112, 112]          16,448\n",
      "      BatchNorm2d-19         [-1, 64, 112, 112]             128\n",
      "             ReLU-20         [-1, 64, 112, 112]               0\n",
      "           Conv2d-21         [-1, 64, 112, 112]          36,928\n",
      "      BatchNorm2d-22         [-1, 64, 112, 112]             128\n",
      "             ReLU-23         [-1, 64, 112, 112]               0\n",
      "           Conv2d-24        [-1, 256, 112, 112]          16,640\n",
      "       BottleNeck-25        [-1, 256, 112, 112]               0\n",
      "      BatchNorm2d-26        [-1, 256, 112, 112]             512\n",
      "             ReLU-27        [-1, 256, 112, 112]               0\n",
      "           Conv2d-28         [-1, 64, 112, 112]          16,448\n",
      "      BatchNorm2d-29         [-1, 64, 112, 112]             128\n",
      "             ReLU-30         [-1, 64, 112, 112]               0\n",
      "           Conv2d-31         [-1, 64, 112, 112]          36,928\n",
      "      BatchNorm2d-32         [-1, 64, 112, 112]             128\n",
      "             ReLU-33         [-1, 64, 112, 112]               0\n",
      "           Conv2d-34        [-1, 256, 112, 112]          16,640\n",
      "       BottleNeck-35        [-1, 256, 112, 112]               0\n",
      "      BatchNorm2d-36        [-1, 256, 112, 112]             512\n",
      "             ReLU-37        [-1, 256, 112, 112]               0\n",
      "           Conv2d-38          [-1, 128, 56, 56]          32,896\n",
      "      BatchNorm2d-39          [-1, 128, 56, 56]             256\n",
      "             ReLU-40          [-1, 128, 56, 56]               0\n",
      "           Conv2d-41          [-1, 128, 56, 56]         147,584\n",
      "      BatchNorm2d-42          [-1, 128, 56, 56]             256\n",
      "             ReLU-43          [-1, 128, 56, 56]               0\n",
      "           Conv2d-44          [-1, 512, 56, 56]          66,048\n",
      "           Conv2d-45          [-1, 512, 56, 56]         131,584\n",
      "       BottleNeck-46          [-1, 512, 56, 56]               0\n",
      "      BatchNorm2d-47          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-48          [-1, 512, 56, 56]               0\n",
      "           Conv2d-49          [-1, 128, 56, 56]          65,664\n",
      "      BatchNorm2d-50          [-1, 128, 56, 56]             256\n",
      "             ReLU-51          [-1, 128, 56, 56]               0\n",
      "           Conv2d-52          [-1, 128, 56, 56]         147,584\n",
      "      BatchNorm2d-53          [-1, 128, 56, 56]             256\n",
      "             ReLU-54          [-1, 128, 56, 56]               0\n",
      "           Conv2d-55          [-1, 512, 56, 56]          66,048\n",
      "       BottleNeck-56          [-1, 512, 56, 56]               0\n",
      "      BatchNorm2d-57          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-58          [-1, 512, 56, 56]               0\n",
      "           Conv2d-59          [-1, 128, 56, 56]          65,664\n",
      "      BatchNorm2d-60          [-1, 128, 56, 56]             256\n",
      "             ReLU-61          [-1, 128, 56, 56]               0\n",
      "           Conv2d-62          [-1, 128, 56, 56]         147,584\n",
      "      BatchNorm2d-63          [-1, 128, 56, 56]             256\n",
      "             ReLU-64          [-1, 128, 56, 56]               0\n",
      "           Conv2d-65          [-1, 512, 56, 56]          66,048\n",
      "       BottleNeck-66          [-1, 512, 56, 56]               0\n",
      "      BatchNorm2d-67          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-68          [-1, 512, 56, 56]               0\n",
      "           Conv2d-69          [-1, 128, 56, 56]          65,664\n",
      "      BatchNorm2d-70          [-1, 128, 56, 56]             256\n",
      "             ReLU-71          [-1, 128, 56, 56]               0\n",
      "           Conv2d-72          [-1, 128, 56, 56]         147,584\n",
      "      BatchNorm2d-73          [-1, 128, 56, 56]             256\n",
      "             ReLU-74          [-1, 128, 56, 56]               0\n",
      "           Conv2d-75          [-1, 512, 56, 56]          66,048\n",
      "       BottleNeck-76          [-1, 512, 56, 56]               0\n",
      "      BatchNorm2d-77          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-78          [-1, 512, 56, 56]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,328\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 28, 28]         590,080\n",
      "      BatchNorm2d-83          [-1, 256, 28, 28]             512\n",
      "             ReLU-84          [-1, 256, 28, 28]               0\n",
      "           Conv2d-85         [-1, 1024, 28, 28]         263,168\n",
      "           Conv2d-86         [-1, 1024, 28, 28]         525,312\n",
      "       BottleNeck-87         [-1, 1024, 28, 28]               0\n",
      "      BatchNorm2d-88         [-1, 1024, 28, 28]           2,048\n",
      "             ReLU-89         [-1, 1024, 28, 28]               0\n",
      "           Conv2d-90          [-1, 256, 28, 28]         262,400\n",
      "      BatchNorm2d-91          [-1, 256, 28, 28]             512\n",
      "             ReLU-92          [-1, 256, 28, 28]               0\n",
      "           Conv2d-93          [-1, 256, 28, 28]         590,080\n",
      "      BatchNorm2d-94          [-1, 256, 28, 28]             512\n",
      "             ReLU-95          [-1, 256, 28, 28]               0\n",
      "           Conv2d-96         [-1, 1024, 28, 28]         263,168\n",
      "       BottleNeck-97         [-1, 1024, 28, 28]               0\n",
      "      BatchNorm2d-98         [-1, 1024, 28, 28]           2,048\n",
      "             ReLU-99         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-100          [-1, 256, 28, 28]         262,400\n",
      "     BatchNorm2d-101          [-1, 256, 28, 28]             512\n",
      "            ReLU-102          [-1, 256, 28, 28]               0\n",
      "          Conv2d-103          [-1, 256, 28, 28]         590,080\n",
      "     BatchNorm2d-104          [-1, 256, 28, 28]             512\n",
      "            ReLU-105          [-1, 256, 28, 28]               0\n",
      "          Conv2d-106         [-1, 1024, 28, 28]         263,168\n",
      "      BottleNeck-107         [-1, 1024, 28, 28]               0\n",
      "     BatchNorm2d-108         [-1, 1024, 28, 28]           2,048\n",
      "            ReLU-109         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-110          [-1, 256, 28, 28]         262,400\n",
      "     BatchNorm2d-111          [-1, 256, 28, 28]             512\n",
      "            ReLU-112          [-1, 256, 28, 28]               0\n",
      "          Conv2d-113          [-1, 256, 28, 28]         590,080\n",
      "     BatchNorm2d-114          [-1, 256, 28, 28]             512\n",
      "            ReLU-115          [-1, 256, 28, 28]               0\n",
      "          Conv2d-116         [-1, 1024, 28, 28]         263,168\n",
      "      BottleNeck-117         [-1, 1024, 28, 28]               0\n",
      "     BatchNorm2d-118         [-1, 1024, 28, 28]           2,048\n",
      "            ReLU-119         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-120          [-1, 256, 28, 28]         262,400\n",
      "     BatchNorm2d-121          [-1, 256, 28, 28]             512\n",
      "            ReLU-122          [-1, 256, 28, 28]               0\n",
      "          Conv2d-123          [-1, 256, 28, 28]         590,080\n",
      "     BatchNorm2d-124          [-1, 256, 28, 28]             512\n",
      "            ReLU-125          [-1, 256, 28, 28]               0\n",
      "          Conv2d-126         [-1, 1024, 28, 28]         263,168\n",
      "      BottleNeck-127         [-1, 1024, 28, 28]               0\n",
      "     BatchNorm2d-128         [-1, 1024, 28, 28]           2,048\n",
      "            ReLU-129         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-130          [-1, 256, 28, 28]         262,400\n",
      "     BatchNorm2d-131          [-1, 256, 28, 28]             512\n",
      "            ReLU-132          [-1, 256, 28, 28]               0\n",
      "          Conv2d-133          [-1, 256, 28, 28]         590,080\n",
      "     BatchNorm2d-134          [-1, 256, 28, 28]             512\n",
      "            ReLU-135          [-1, 256, 28, 28]               0\n",
      "          Conv2d-136         [-1, 1024, 28, 28]         263,168\n",
      "      BottleNeck-137         [-1, 1024, 28, 28]               0\n",
      "     BatchNorm2d-138         [-1, 1024, 28, 28]           2,048\n",
      "            ReLU-139         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-140          [-1, 512, 14, 14]         524,800\n",
      "     BatchNorm2d-141          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-142          [-1, 512, 14, 14]               0\n",
      "          Conv2d-143          [-1, 512, 14, 14]       2,359,808\n",
      "     BatchNorm2d-144          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-145          [-1, 512, 14, 14]               0\n",
      "          Conv2d-146         [-1, 2048, 14, 14]       1,050,624\n",
      "          Conv2d-147         [-1, 2048, 14, 14]       2,099,200\n",
      "      BottleNeck-148         [-1, 2048, 14, 14]               0\n",
      "     BatchNorm2d-149         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-150         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-151          [-1, 512, 14, 14]       1,049,088\n",
      "     BatchNorm2d-152          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-153          [-1, 512, 14, 14]               0\n",
      "          Conv2d-154          [-1, 512, 14, 14]       2,359,808\n",
      "     BatchNorm2d-155          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-156          [-1, 512, 14, 14]               0\n",
      "          Conv2d-157         [-1, 2048, 14, 14]       1,050,624\n",
      "      BottleNeck-158         [-1, 2048, 14, 14]               0\n",
      "     BatchNorm2d-159         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-160         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-161          [-1, 512, 14, 14]       1,049,088\n",
      "     BatchNorm2d-162          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-163          [-1, 512, 14, 14]               0\n",
      "          Conv2d-164          [-1, 512, 14, 14]       2,359,808\n",
      "     BatchNorm2d-165          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-166          [-1, 512, 14, 14]               0\n",
      "          Conv2d-167         [-1, 2048, 14, 14]       1,050,624\n",
      "      BottleNeck-168         [-1, 2048, 14, 14]               0\n",
      "AdaptiveAvgPool2d-169           [-1, 2048, 1, 1]               0\n",
      "          Linear-170                   [-1, 10]          20,490\n",
      "================================================================\n",
      "Total params: 23,535,754\n",
      "Trainable params: 23,535,754\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 1058.11\n",
      "Params size (MB): 89.78\n",
      "Estimated Total Size (MB): 1148.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class BottleNeck(nn.Module):\n",
    "    # channel 변화: in_channels -> out_channels * expansion\n",
    "    # residual + shortcut => 출력\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super().__init__()\n",
    "        \n",
    "        # residual: in_channels -> out_channels * expansion\n",
    "        \n",
    "        self.residual = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, \n",
    "                      1, stride=stride),\n",
    "            \n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels,\n",
    "                      3, stride=1, padding=1),\n",
    "            \n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, \n",
    "                      1)\n",
    "        )\n",
    "        \n",
    "        # shortcut: in_channels -> out_channels * expansion\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Conv2d(in_channels, out_channels * BottleNeck.expansion,\n",
    "                                      1, stride=stride)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.residual(x)\n",
    "        out += self.shortcut(x)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class PreActResNet(nn.Module):\n",
    "    def __init__(self, num_blocks, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64,\n",
    "                      3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2, 1)\n",
    "        )\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv2 = self._make_layers(num_blocks[0], 64, 1)\n",
    "        self.conv3 = self._make_layers(num_blocks[1], 128, 2)\n",
    "        self.conv4 = self._make_layers(num_blocks[2], 256, 2)\n",
    "        self.conv5 = self._make_layers(num_blocks[3], 512, 2)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.fc = nn.Linear(512 * BottleNeck.expansion, num_classes)\n",
    "        \n",
    "    def _make_layers(self, num_blocks, out_channels, stride):\n",
    "        layers = []\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        \n",
    "        for stride in strides:\n",
    "            layers.append(BottleNeck(self.in_channels, out_channels, stride))\n",
    "            \n",
    "            self.in_channels = out_channels * BottleNeck.expansion # 현재 layer의 출력 channel 개수를 바로다음 layer의 입력 channel 개수로 넘겨줌\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        \n",
    "        x = self.avg_pool(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def PreActResNet50():\n",
    "    return PreActResNet([3, 4, 6, 3])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = PreActResNet50().to(device)\n",
    "\n",
    "summary(model, (3, 224, 224))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
